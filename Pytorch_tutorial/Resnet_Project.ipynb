{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Regina-Arthur/Python-Coding-Projects/blob/main/Pytorch_tutorial/Resnet_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SP2pLXXiILkn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import  Subset\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jBhDhmqDiVc2"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AZVTj0HGHyj5"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4  # last Conv expands channels by 4×\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "        # 1x1 Conv (reduce dimensions)\n",
        "        self.conv1 = nn.Conv2d(in_channels= in_channels, out_channels= out_channels, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # 3x3 Conv (main spatial conv)\n",
        "        self.conv2 = nn.Conv2d(in_channels= out_channels, out_channels= out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # 1x1 Conv (expand back up)\n",
        "        self.conv3 = nn.Conv2d(in_channels= out_channels, out_channels= out_channels * self.expansion, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample  # used if input/output dims don’t match\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x  # save input for skip connection\n",
        "\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "\n",
        "        # adjust dimensions if needed\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity  # skip connection\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet50(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initial conv layer\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Residual stages\n",
        "        self.layer1 = self._make_layer(in_channels= 64, out_channels= 64, blocks=3, stride=1)   # 256 out\n",
        "        self.layer2 = self._make_layer(in_channels= 256, out_channels= 128, blocks=4, stride=2) # 512 out\n",
        "        self.layer3 = self._make_layer(in_channels= 512, out_channels= 256, blocks=6, stride=2) # 1024 out\n",
        "        self.layer4 = self._make_layer(in_channels= 1024, out_channels= 512, blocks=3, stride=2)# 2048 out\n",
        "\n",
        "        # Final classification head\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Global AvgPool\n",
        "        self.fc = nn.Linear(512 * Bottleneck.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, blocks, stride):\n",
        "        \"\"\"Builds one stage with multiple bottleneck blocks\"\"\"\n",
        "        downsample = None\n",
        "        if stride != 1 or in_channels != out_channels * Bottleneck.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * Bottleneck.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * Bottleneck.expansion)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(Bottleneck(in_channels, out_channels, stride, downsample))\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(Bottleneck(out_channels * Bottleneck.expansion, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Stages\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        # Head\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-1Qkq0pXEtQ",
        "outputId": "e88d1b9b-8719-4639-ba39-bae47daa8389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWy-77iFzMUL"
      },
      "outputs": [],
      "source": [
        "# # from google.colab import drive\n",
        "# # drive.mount('/content/drive')\n",
        "\n",
        "# zip_file_path = '/content/drive/My Drive/Concrete.rar'  # Replace with your zip file's path\n",
        "# extract_path = '/content/drive/My Drive/concrete_data'  # Desired directory for extracted files\n",
        "\n",
        "# import os\n",
        "# os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# !apt-get install unrar\n",
        "# !unrar x -o+ \"$zip_file_path\" \"$extract_path\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eCM5p1NXMx_b"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.PILToTensor(),\n",
        "    transforms.ConvertImageDtype(torch.float)\n",
        "])\n",
        "\n",
        "data = \"/content/drive/My Drive/concrete_data\"\n",
        "\n",
        "# ImageFolder to load data with folder names as class names\n",
        "dataset = datasets.ImageFolder(root=data, transform=transform)\n",
        "\n",
        "# Group indices by class\n",
        "class_indices = {cls: [] for cls in range(len(dataset.classes))}\n",
        "for idx, (_, label) in enumerate(dataset.samples):\n",
        "    class_indices[label].append(idx)\n",
        "\n",
        "# Take the first 100 per class (sorted order)\n",
        "selected_indices = []\n",
        "for cls, indices in class_indices.items():\n",
        "    indices.sort()  # make sure it's in consistent order\n",
        "    selected_indices.extend(indices[:100])  # take first 100\n",
        "\n",
        "# Create train subset\n",
        "train = Subset(dataset, selected_indices)\n",
        "\n",
        "# Take the 50 per class (sorted order)\n",
        "selected_indices = []\n",
        "for cls, indices in class_indices.items():\n",
        "    indices.sort()  # make sure it's in consistent order\n",
        "    selected_indices.extend(indices[500:551])\n",
        "\n",
        "# Create test subset\n",
        "val = Subset(dataset, selected_indices)\n",
        "\n",
        "# Take the 50 per class (sorted order)\n",
        "selected_indices = []\n",
        "for cls, indices in class_indices.items():\n",
        "    indices.sort()  # make sure it's in consistent order\n",
        "    selected_indices.extend(indices[551:601])\n",
        "\n",
        "# Create test subset\n",
        "test = Subset(dataset, selected_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypBdp1MCitRQ",
        "outputId": "f5d80d02-f588-4e20-fb7e-caa1cf3dd6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 100, train loss = 0.30703810256506714, train accuracy = 83.5\n",
            "Epoch 2 / 100, train loss = 0.13691701234451362, train accuracy = 96.0\n",
            "Epoch 3 / 100, train loss = 0.1655124332755804, train accuracy = 94.0\n",
            "Epoch 4 / 100, train loss = 0.07168662082403898, train accuracy = 97.5\n",
            "Epoch 5 / 100, train loss = 0.06365487019398383, train accuracy = 98.0\n",
            "Epoch 6 / 100, train loss = 0.038078324403613806, train accuracy = 98.0\n",
            "Epoch 7 / 100, train loss = 0.04065458772570959, train accuracy = 99.5\n",
            "Epoch 8 / 100, train loss = 0.011375651969241776, train accuracy = 99.0\n",
            "Epoch 9 / 100, train loss = 0.05740310852083245, train accuracy = 99.5\n",
            "Epoch 10 / 100, train loss = 0.04420926927455834, train accuracy = 99.5\n",
            "Epoch 11 / 100, train loss = 0.07329497812315822, train accuracy = 98.0\n",
            "Epoch 12 / 100, train loss = 0.04403521157135921, train accuracy = 98.5\n",
            "Epoch 13 / 100, train loss = 0.22776437239787942, train accuracy = 95.5\n",
            "Epoch 14 / 100, train loss = 0.13377109781972, train accuracy = 97.0\n",
            "Epoch 15 / 100, train loss = 0.034826626834858744, train accuracy = 98.5\n",
            "Epoch 16 / 100, train loss = 0.026109837594309022, train accuracy = 99.0\n",
            "Epoch 17 / 100, train loss = 0.005342298952330436, train accuracy = 100.0\n",
            "Epoch 18 / 100, train loss = 0.013099119316653482, train accuracy = 99.5\n",
            "Epoch 19 / 100, train loss = 0.00572728320756661, train accuracy = 100.0\n",
            "Epoch 20 / 100, train loss = 0.009158552025577851, train accuracy = 100.0\n",
            "Epoch 21 / 100, train loss = 0.0016038601897889748, train accuracy = 100.0\n",
            "Epoch 22 / 100, train loss = 0.01320208099995008, train accuracy = 99.5\n",
            "Epoch 23 / 100, train loss = 0.00034650423705378283, train accuracy = 100.0\n",
            "Epoch 24 / 100, train loss = 0.0003262189483003957, train accuracy = 100.0\n",
            "Epoch 25 / 100, train loss = 0.0006218448272972767, train accuracy = 100.0\n",
            "Epoch 26 / 100, train loss = 0.0005539608038296657, train accuracy = 100.0\n",
            "Epoch 27 / 100, train loss = 0.0014574444170908204, train accuracy = 100.0\n",
            "Epoch 28 / 100, train loss = 0.00021174376992608553, train accuracy = 100.0\n",
            "Epoch 29 / 100, train loss = 0.00023319994215853512, train accuracy = 100.0\n",
            "Epoch 30 / 100, train loss = 0.0001731522269048063, train accuracy = 100.0\n",
            "Epoch 31 / 100, train loss = 0.0002530573713426877, train accuracy = 100.0\n",
            "Epoch 32 / 100, train loss = 0.00013551297368914156, train accuracy = 100.0\n",
            "Epoch 33 / 100, train loss = 0.00016425002208312174, train accuracy = 100.0\n",
            "Epoch 34 / 100, train loss = 0.00013755520922131836, train accuracy = 100.0\n",
            "Epoch 35 / 100, train loss = 0.0017502003127966809, train accuracy = 100.0\n",
            "Epoch 36 / 100, train loss = 0.00018010024255740324, train accuracy = 100.0\n",
            "Epoch 37 / 100, train loss = 7.965941663964518e-05, train accuracy = 100.0\n",
            "Epoch 38 / 100, train loss = 0.0007559817900723179, train accuracy = 100.0\n",
            "Epoch 39 / 100, train loss = 0.0001004872158643723, train accuracy = 100.0\n",
            "Epoch 40 / 100, train loss = 9.117397062904533e-05, train accuracy = 100.0\n",
            "Epoch 41 / 100, train loss = 0.01809046995731478, train accuracy = 99.5\n",
            "Epoch 42 / 100, train loss = 0.003487308740399645, train accuracy = 100.0\n",
            "Epoch 43 / 100, train loss = 0.019079566367768815, train accuracy = 100.0\n",
            "Epoch 44 / 100, train loss = 0.0027433766185172965, train accuracy = 100.0\n",
            "Epoch 45 / 100, train loss = 0.0037595449497790207, train accuracy = 100.0\n",
            "Epoch 46 / 100, train loss = 0.0008515471792114633, train accuracy = 100.0\n",
            "Epoch 47 / 100, train loss = 0.001139997284293973, train accuracy = 100.0\n",
            "Epoch 48 / 100, train loss = 0.0010265934106428176, train accuracy = 100.0\n",
            "Epoch 49 / 100, train loss = 0.0002849909973779826, train accuracy = 100.0\n",
            "Epoch 50 / 100, train loss = 0.0011442164042299347, train accuracy = 100.0\n",
            "Epoch 51 / 100, train loss = 0.00034525852918574983, train accuracy = 100.0\n",
            "Epoch 52 / 100, train loss = 0.00017946253293692798, train accuracy = 100.0\n",
            "Epoch 53 / 100, train loss = 0.00011675820652661579, train accuracy = 100.0\n",
            "Epoch 54 / 100, train loss = 0.00018832788139531788, train accuracy = 100.0\n",
            "Epoch 55 / 100, train loss = 0.10049647019384013, train accuracy = 99.5\n",
            "Epoch 56 / 100, train loss = 0.03477013893383888, train accuracy = 98.0\n",
            "Epoch 57 / 100, train loss = 0.027079989019382213, train accuracy = 98.0\n",
            "Epoch 58 / 100, train loss = 0.014960043065782105, train accuracy = 100.0\n",
            "Epoch 59 / 100, train loss = 0.004914654901118151, train accuracy = 100.0\n",
            "Epoch 60 / 100, train loss = 0.0027972648801681188, train accuracy = 100.0\n",
            "Epoch 61 / 100, train loss = 0.05162979613773392, train accuracy = 99.0\n",
            "Epoch 62 / 100, train loss = 0.08756685846830285, train accuracy = 98.0\n",
            "Epoch 63 / 100, train loss = 0.011551800412624809, train accuracy = 99.5\n",
            "Epoch 64 / 100, train loss = 0.020709722668730786, train accuracy = 99.5\n",
            "Epoch 65 / 100, train loss = 0.018547213686230992, train accuracy = 99.5\n",
            "Epoch 66 / 100, train loss = 0.011853267995840204, train accuracy = 100.0\n",
            "Epoch 67 / 100, train loss = 0.0010537398172475929, train accuracy = 100.0\n",
            "Epoch 68 / 100, train loss = 0.0006198770819797314, train accuracy = 100.0\n",
            "Epoch 69 / 100, train loss = 0.0018813867354765534, train accuracy = 100.0\n",
            "Epoch 70 / 100, train loss = 0.0016754143788213177, train accuracy = 100.0\n",
            "Epoch 71 / 100, train loss = 0.0004754478723043576, train accuracy = 100.0\n",
            "Epoch 72 / 100, train loss = 0.0008199892285379715, train accuracy = 100.0\n",
            "Epoch 73 / 100, train loss = 0.0004636264857253991, train accuracy = 100.0\n",
            "Epoch 74 / 100, train loss = 0.0007259586927830242, train accuracy = 100.0\n",
            "Epoch 75 / 100, train loss = 0.0003625155451507973, train accuracy = 100.0\n",
            "Epoch 76 / 100, train loss = 0.00036937209863806075, train accuracy = 100.0\n",
            "Epoch 77 / 100, train loss = 0.0001856354283518158, train accuracy = 100.0\n",
            "Epoch 78 / 100, train loss = 0.00018981317251538194, train accuracy = 100.0\n",
            "Epoch 79 / 100, train loss = 0.0002244429295907529, train accuracy = 100.0\n",
            "Epoch 80 / 100, train loss = 0.0001361380158674105, train accuracy = 100.0\n",
            "Epoch 81 / 100, train loss = 0.00016738588159829045, train accuracy = 100.0\n",
            "Epoch 82 / 100, train loss = 0.00019670295439157468, train accuracy = 100.0\n",
            "Epoch 83 / 100, train loss = 0.00010570392883632198, train accuracy = 100.0\n",
            "Epoch 84 / 100, train loss = 0.004547220563316452, train accuracy = 99.5\n",
            "Epoch 85 / 100, train loss = 0.007437628808994694, train accuracy = 99.5\n",
            "Epoch 86 / 100, train loss = 0.00014879445097903954, train accuracy = 100.0\n",
            "Epoch 87 / 100, train loss = 0.00048486660047534054, train accuracy = 100.0\n",
            "Epoch 88 / 100, train loss = 0.00021327756465845077, train accuracy = 100.0\n",
            "Epoch 89 / 100, train loss = 0.00011945246530688434, train accuracy = 100.0\n",
            "Epoch 90 / 100, train loss = 0.00038929063469238045, train accuracy = 100.0\n",
            "Epoch 91 / 100, train loss = 0.01896062418693743, train accuracy = 99.5\n",
            "Epoch 92 / 100, train loss = 0.024935640168093545, train accuracy = 98.5\n",
            "Epoch 93 / 100, train loss = 0.061430341040249914, train accuracy = 99.0\n",
            "Epoch 94 / 100, train loss = 0.08110515773296356, train accuracy = 97.5\n",
            "Epoch 95 / 100, train loss = 0.056846121159781306, train accuracy = 98.5\n",
            "Epoch 96 / 100, train loss = 0.03969661104825458, train accuracy = 99.0\n",
            "Epoch 97 / 100, train loss = 0.008735986742457109, train accuracy = 99.5\n",
            "Epoch 98 / 100, train loss = 0.0026047507001619253, train accuracy = 100.0\n",
            "Epoch 99 / 100, train loss = 0.001943185314303264, train accuracy = 100.0\n",
            "Epoch 100 / 100, train loss = 0.0007648414715991489, train accuracy = 100.0\n",
            "Epoch 1/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 2/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 3/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 4/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 5/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0053, Val Acc: 99.02%\n",
            "Epoch 6/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 7/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0054, Val Acc: 99.02%\n",
            "Epoch 8/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 9/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0055, Val Acc: 99.02%\n",
            "Epoch 10/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 11/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 12/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0060, Val Acc: 99.02%\n",
            "Epoch 13/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 14/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 15/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 16/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0060, Val Acc: 99.02%\n",
            "Epoch 17/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 18/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 19/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0055, Val Acc: 99.02%\n",
            "Epoch 20/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 21/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 22/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0055, Val Acc: 99.02%\n",
            "Epoch 23/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 24/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 25/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 26/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0056, Val Acc: 99.02%\n",
            "Epoch 27/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 28/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 29/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 30/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 31/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 32/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 33/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 34/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 35/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 36/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 37/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0055, Val Acc: 99.02%\n",
            "Epoch 38/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 39/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 40/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 41/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 42/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 43/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 44/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 45/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0060, Val Acc: 99.02%\n",
            "Epoch 46/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 47/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 48/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 49/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 50/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 51/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 52/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 53/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 54/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 55/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 56/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 57/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 58/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 59/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 60/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 61/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 62/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 63/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 64/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 65/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 66/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 67/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 68/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 69/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 70/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 71/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 72/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 73/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 74/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 75/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 76/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 77/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 78/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 79/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 80/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 81/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 82/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 83/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 84/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 85/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0254, Val Acc: 99.02%\n",
            "Epoch 86/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 87/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 88/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 89/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 90/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 91/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 92/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 93/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 94/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 95/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 96/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0060, Val Acc: 99.02%\n",
            "Epoch 97/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 98/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0052, Val Acc: 99.02%\n",
            "Epoch 99/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 100/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%\n",
            "Epoch 1/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 2/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 3/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 4/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 5/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 6/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 7/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 8/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 9/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 10/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 11/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 12/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 13/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 14/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 15/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 16/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 17/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 18/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 19/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 20/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 21/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 22/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 23/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 24/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 25/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 26/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 27/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 28/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 29/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 30/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 31/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 32/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 33/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 34/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 35/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 36/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 37/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 38/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 39/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 40/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 41/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 42/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 43/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 44/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 45/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 46/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 47/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 48/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 49/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 50/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 51/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 52/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 53/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 54/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 55/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 56/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 57/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 58/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 59/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 60/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 61/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 62/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 63/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 64/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 65/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 66/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 67/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 68/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 69/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 70/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 71/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 72/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 73/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 74/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 75/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 76/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 77/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 78/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 79/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 80/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 81/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 82/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 83/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 84/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 85/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 86/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 87/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 88/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 89/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 90/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 91/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 92/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 93/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 94/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 95/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 96/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 97/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 98/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 99/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n",
            "Epoch 100/100 | Train Loss: 0.0008, Train Acc: 100.00% | Val Loss: 0.0051, Val Acc: 99.02%Test loss: 0.0036, Test Acc: 99.00%\n"
          ]
        }
      ],
      "source": [
        "model = ResNet50()\n",
        "model.to(device)\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for images, labels in train_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    train_loss = loss(outputs, labels)\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += train_loss.item()\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  train_loss = running_loss/ len(train_loader)\n",
        "  train_accuracy = 100* correct/total\n",
        "\n",
        "  print(f\"Epoch {epoch+1} / {epochs}, train loss = {train_loss}, train accuracy = {train_accuracy}\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for images, labels in val_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    val_loss = loss(outputs, labels)\n",
        "    running_loss += val_loss.item()\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  val_loss = running_loss/ len(train_loader)\n",
        "  val_accuracy = 100* correct/total\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}% | \"\n",
        "            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    test_loss = loss(outputs, labels)\n",
        "    running_loss += test_loss.item()\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  test_loss = running_loss/ len(train_loader)\n",
        "  test_accuracy = 100* correct/total\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}% | \"\n",
        "            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\"\n",
        "            f\"Test loss: {test_loss:.4f}, Test Acc: {test_accuracy:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyO6cqE5tgK43e0zhKA4ttzG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}